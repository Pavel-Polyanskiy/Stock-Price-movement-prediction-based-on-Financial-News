{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import finnhub\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yahoo_fin import stock_info\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import date,timedelta\n",
    "from yahoo_fin import stock_info\n",
    "import re\n",
    "import nltk\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "company_name = 'Apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finnhub_client = finnhub.Client(api_key = \"c7i4q2qad3if83qgdfl0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_news(ticker):\n",
    "    news = []\n",
    "    initial_date = datetime.now().date()\n",
    "    offset = (pd.to_datetime(initial_date) - pd.DateOffset(days = 1)).strftime('%Y-%m-%d')\n",
    "    news_iter = finnhub_client.company_news(ticker, _from = offset, to = initial_date)\n",
    "    news += news_iter\n",
    "\n",
    "    #initial_date = (pd.to_datetime(offset) - pd.DateOffset(days = 1)).strftime('%Y-%m-%d')\n",
    "\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL news is parsed!\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "tickers = [ticker]\n",
    "for ticker in tickers:\n",
    "    start = time.time()\n",
    "    data[ticker] = get_company_news(ticker)\n",
    "    end = time.time() - start\n",
    "    print(f'{ticker} news is parsed!')\n",
    "    #print(f'Sleeping for {np.round((62 - end), 0)} seconds...')\n",
    "    #time.sleep((60 - end))\n",
    "    if ticker != tickers[-1]:\n",
    "        time.sleep(70)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAPL'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the correctness\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в 19 строчке надо определить время, после которого отсекать\n",
    "def get_news_dataset(ticker, company_name):\n",
    "    #extracting news from dictionary \n",
    "    news = pd.DataFrame(data[ticker])\n",
    "    news['datetime'] = news['datetime'].apply(lambda date: datetime.utcfromtimestamp(date).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    #only news with ticker occurance\n",
    "    news = news[news.headline.str.contains(company_name)].reset_index(drop = True)\n",
    "\n",
    "    #GMT-to-EST correction\n",
    "    news['datetime'] = news['datetime'].apply(lambda date: pd.to_datetime(date) - pd.DateOffset(hours = 5))\n",
    "    \n",
    "    #next day correction\n",
    "    timestamps = news['datetime'] \n",
    "    timestamps_new = []\n",
    "    for date in timestamps:\n",
    "        date = date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if pd.to_datetime(date) > pd.to_datetime(f'{date[:10]} 10:00:00'):\n",
    "            date = pd.to_datetime(date)\n",
    "            date_new = (date - timedelta(hours = date.hour, minutes = date.minute,\n",
    "                    seconds = date.second)) + timedelta(days = 1)\n",
    "            timestamps_new.append(date_new.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        else:\n",
    "            timestamps_new.append(date)\n",
    "\n",
    "\n",
    "    news['datetime'] = timestamps_new\n",
    "    \n",
    "    news = news[['datetime', 'headline', 'source', 'summary']]\n",
    "    news['datetime'] = news['datetime'].apply(lambda date: pd.to_datetime(date).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    #trading days only\n",
    "    bdays = pd.bdate_range(start = news['datetime'].to_list()[-1], \n",
    "               end = news['datetime'][0])\n",
    "\n",
    "    bdays = pd.DataFrame(bdays, columns = ['datetime'])\n",
    "\n",
    "    bdays.datetime = bdays.datetime.astype('str')\n",
    "\n",
    "    news_filtered = pd.merge(news, bdays, how = 'right')\n",
    "    \n",
    "    #dropping dublicates\n",
    "    news_filtered.drop_duplicates(['headline'], ignore_index = True, inplace = True)\n",
    "    \n",
    "    return news_filtered\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-restriction",
   "metadata": {},
   "source": [
    "# Financials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-factor",
   "metadata": {},
   "source": [
    "#### Relative Strength Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prepared-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#здесь выбрать какое среднее брать - обычное или эксп\n",
    "def rsi(historical_data, window):\n",
    "    changes = historical_data['adjclose'].diff(periods = 1)\n",
    "    gain, loss = changes.clip(lower = 0), changes.clip(upper = 0).abs()\n",
    "    \n",
    "    #rsi based on SMA\n",
    "    rolling_gain = gain.rolling(window, closed = 'left').mean()\n",
    "    rolling_loss = loss.rolling(window, closed = 'left').mean()\n",
    "    \n",
    "    rs = rolling_gain / rolling_loss\n",
    "    rsi_sma = 100.0 - (100.0 / (1.0 + rs))\n",
    "    \n",
    "    #rsi based on EMA\n",
    "    rolling_gain_exp = rolling_gain.ewm(span = window).mean()\n",
    "    rolling_loss_exp = rolling_loss.ewm(span = window).mean()\n",
    "\n",
    "    rs_exp = rolling_gain_exp / rolling_loss_exp\n",
    "    rsi_ema = 100.0 - (100.0 / (1.0 + rs_exp))\n",
    "    \n",
    "    return rsi_sma, rsi_ema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-tennessee",
   "metadata": {},
   "source": [
    "#### Financial indicators for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "upper-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_indicators(historical_data):\n",
    "    df = {}\n",
    "    data = historical_data['adjclose']\n",
    "    df['datetime'] = historical_data['adjclose'].index\n",
    "    df['adjclose'] = data\n",
    "    #10 days Moving Average\n",
    "    df['ma_10'] = data.rolling(window = 10, closed = 'left').mean()[10:]\n",
    "    #20 days Moving Average\n",
    "    df['ma_20'] = data.rolling(window = 20, closed = 'left').mean()[20:]\n",
    "    #10 days Moving Average\n",
    "    df['ma_30'] = data.rolling(window = 30, closed = 'left').mean()[30:]\n",
    "    \n",
    "    #12 days Exponential Moving Average\n",
    "    df['ema_12'] = data.ewm(span = 12).mean()[1:]\n",
    "    df['ema_12'] =  df['ema_12'].shift()\n",
    "    #26 days Exponential Moving Average\n",
    "    df['ema_26'] = data.ewm(span = 26).mean()[1:]\n",
    "    df['ema_26'] =  df['ema_26'].shift()\n",
    "    #6 days Relative Strength Index\n",
    "    df['rsi_6_sma'], df['rsi_6_ema'] = rsi(historical_data, window = 6)\n",
    "    #12 days Relative Strength Index\n",
    "    df['rsi_12_sma'], df['rsi_12_ema'] = rsi(historical_data, window = 12)\n",
    "    #24 days Relative Strength Index\n",
    "    df['rsi_24_sma'], df['rsi_24_ema'] = rsi(historical_data, window = 24)\n",
    "    \n",
    "    final_df = pd.DataFrame(df)\n",
    "   \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "given-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financials_dataset(ticker):\n",
    "    #historical data\n",
    "    historical_data = stock_info.get_data(ticker,\n",
    "                                      start_date = pd.to_datetime(news_filtered['datetime'][0]) - \n",
    "                                      pd.DateOffset(days = 100), \n",
    "                                      end_date =  news_filtered['datetime'].to_list()[-1],\n",
    "                                      index_as_date = True, \n",
    "                                      interval = '1d')\n",
    "    \n",
    "    #financial indicators\n",
    "    financials = financial_indicators(historical_data)\n",
    "    financials = financials[financials['datetime'] >= pd.to_datetime(news_filtered.datetime[0])]\n",
    "    financials['datetime'] = financials['datetime'].apply(lambda date: date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    #reseting the index for further concatenation with news dataset\n",
    "    financials.index = financials.index.astype('object')\n",
    "    fin_index = pd.Series(financials.index)\n",
    "    fin_index = fin_index.apply(lambda fin : fin.strftime('%Y-%m-%d'))\n",
    "    financials.set_index(fin_index, drop = True, inplace = True)\n",
    "    \n",
    "    return financials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-blond",
   "metadata": {},
   "source": [
    "### Reshaping the data to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "going-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_news_data(news_filtered):\n",
    "    news_filtered['RANK'] = news_filtered.groupby(\"datetime\")[\"datetime\"].rank(method=\"first\", ascending=True)\n",
    "    news_filtered['RANK'] = news_filtered['RANK'].astype('int')\n",
    "    news_reshaped = news_filtered.pivot(index = 'datetime', values = 'headline', columns = 'RANK')\n",
    "    news_reshaped.columns = [f'news_{index}' for index in news_reshaped.columns]\n",
    "    \n",
    "    return news_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_prediction_data():\n",
    "    #news \n",
    "    news_filtered = get_news_dataset(ticker, company_name)\n",
    "\n",
    "    #historical prices\n",
    "    historical_data = stock_info.get_data(ticker,\n",
    "                                        start_date = pd.to_datetime(news_filtered['datetime'][0]) - \n",
    "                                        pd.DateOffset(days = 100), \n",
    "                                        end_date =  news_filtered['datetime'].to_list()[-1],\n",
    "                                        index_as_date = False, \n",
    "                                        interval = '1d')\n",
    "    historical_data.drop_duplicates('date', inplace = True)\n",
    "    financials = financial_indicators(historical_data).iloc[-1, :]\n",
    "    #news reshaped\n",
    "    news_reshaped = reshape_news_data(news_filtered)\n",
    "    news_reshaped = news_reshaped.iloc[0, :]\n",
    "    financials.name = news_reshaped.name\n",
    "    final_dataframe = pd.concat([news_reshaped, financials], axis = 0, join = 'inner')\n",
    "    index = news_reshaped.index.append(financials.index)\n",
    "    values = news_reshaped.values.tolist() + financials.values.tolist() \n",
    "    df = pd.DataFrame(values).transpose()\n",
    "    df.columns = index\n",
    "    df.drop('datetime', inplace = True, axis = 1)\n",
    "    df.drop(columns = ['rsi_12_ema', 'rsi_24_ema'], axis = 1, inplace = True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['index'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    df.set_index('index', inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(historical_data, predict_trend = True):\n",
    "    historical_data['diff'] = historical_data['adjclose'] - historical_data['open']\n",
    "    movements = historical_data['diff'].apply(lambda price: 1 if price > 0 else 0)\n",
    "    target = pd.DataFrame({'date':historical_data['date'], 'target' : movements}).set_index('date')\n",
    "    \n",
    "    target.index = target.index.astype('object')\n",
    "\n",
    "    target_index = pd.Series(target.index)\n",
    "    target_index = target_index.apply(lambda fin : fin.strftime('%Y-%m-%d'))\n",
    "    target.set_index(target_index, drop = True, inplace = True)\n",
    "    if predict_trend:\n",
    "        #trend\n",
    "        trend = []\n",
    "        i = 0\n",
    "        i_initial = 0\n",
    "        for i in range(len(target) - 1):\n",
    "            try:\n",
    "                if target.target[i]:\n",
    "                    while target.target[i] == 1:\n",
    "                        i += 1\n",
    "\n",
    "                else:\n",
    "                    while target.target[i] == 0:\n",
    "                        i += 1\n",
    "\n",
    "                trend.append(i - i_initial)\n",
    "\n",
    "                i_initial += 1\n",
    "                i = 0\n",
    "            except:\n",
    "                break\n",
    "        #appending trend\n",
    "        target['trend'] = np.NaN\n",
    "        index = len(target) - len(trend)\n",
    "        target['trend'][:-index] = trend\n",
    "        target = target.iloc[:-index, :]\n",
    "\n",
    "        target.trend = target.trend.astype('int')\n",
    "\n",
    "        return target\n",
    "    else:\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_1</th>\n",
       "      <th>news_2</th>\n",
       "      <th>news_3</th>\n",
       "      <th>news_4</th>\n",
       "      <th>news_5</th>\n",
       "      <th>news_6</th>\n",
       "      <th>news_7</th>\n",
       "      <th>news_8</th>\n",
       "      <th>news_9</th>\n",
       "      <th>news_10</th>\n",
       "      <th>...</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>rsi_6_sma</th>\n",
       "      <th>rsi_6_ema</th>\n",
       "      <th>rsi_12_sma</th>\n",
       "      <th>rsi_24_sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>Accused stalker of Apple CEO Tim Cook agrees t...</td>\n",
       "      <td>Dow Jones Opens Higher As Russia, Ukraine Hold...</td>\n",
       "      <td>Apple’s Best Run Since 2003 Brings $3 Trillion...</td>\n",
       "      <td>Here’s Why You Should Consider Investing in Ap...</td>\n",
       "      <td>Justice Department backs Big Tech antitrust bi...</td>\n",
       "      <td>Apple Stock Is on Its Hottest Winning Streak S...</td>\n",
       "      <td>Here's How Analysts View Apple's Latest Produc...</td>\n",
       "      <td>Time to Take Aggressive Apple Profits</td>\n",
       "      <td>Apple : and MLB announce “Friday Night Basebal...</td>\n",
       "      <td>Apple Erases Losses for the Year, on Course fo...</td>\n",
       "      <td>...</td>\n",
       "      <td>178.960007</td>\n",
       "      <td>166.808002</td>\n",
       "      <td>163.54</td>\n",
       "      <td>164.610001</td>\n",
       "      <td>167.910566</td>\n",
       "      <td>166.039017</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.388844</td>\n",
       "      <td>75.973223</td>\n",
       "      <td>58.478654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       news_1  \\\n",
       "index                                                           \n",
       "2022-03-30  Accused stalker of Apple CEO Tim Cook agrees t...   \n",
       "\n",
       "                                                       news_2  \\\n",
       "index                                                           \n",
       "2022-03-30  Dow Jones Opens Higher As Russia, Ukraine Hold...   \n",
       "\n",
       "                                                       news_3  \\\n",
       "index                                                           \n",
       "2022-03-30  Apple’s Best Run Since 2003 Brings $3 Trillion...   \n",
       "\n",
       "                                                       news_4  \\\n",
       "index                                                           \n",
       "2022-03-30  Here’s Why You Should Consider Investing in Ap...   \n",
       "\n",
       "                                                       news_5  \\\n",
       "index                                                           \n",
       "2022-03-30  Justice Department backs Big Tech antitrust bi...   \n",
       "\n",
       "                                                       news_6  \\\n",
       "index                                                           \n",
       "2022-03-30  Apple Stock Is on Its Hottest Winning Streak S...   \n",
       "\n",
       "                                                       news_7  \\\n",
       "index                                                           \n",
       "2022-03-30  Here's How Analysts View Apple's Latest Produc...   \n",
       "\n",
       "                                           news_8  \\\n",
       "index                                               \n",
       "2022-03-30  Time to Take Aggressive Apple Profits   \n",
       "\n",
       "                                                       news_9  \\\n",
       "index                                                           \n",
       "2022-03-30  Apple : and MLB announce “Friday Night Basebal...   \n",
       "\n",
       "                                                      news_10  ...  \\\n",
       "index                                                          ...   \n",
       "2022-03-30  Apple Erases Losses for the Year, on Course fo...  ...   \n",
       "\n",
       "              adjclose       ma_10   ma_20       ma_30      ema_12  \\\n",
       "index                                                                \n",
       "2022-03-30  178.960007  166.808002  163.54  164.610001  167.910566   \n",
       "\n",
       "                ema_26 rsi_6_sma  rsi_6_ema rsi_12_sma rsi_24_sma  \n",
       "index                                                              \n",
       "2022-03-30  166.039017     100.0  88.388844  75.973223  58.478654  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_single_prediction_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_single_prediction_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment and Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = df[[col for col in df.columns if col.startswith('news')]]\n",
    "news = news.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "def clean_data_single_prediction(df):\n",
    "    news = df[[col for col in df.columns if col.startswith('news')]]\n",
    "    news = news.values.tolist()[0]\n",
    "    news_cleaned = []\n",
    "    news_per_day = []\n",
    "    for text in news:\n",
    "        text = re.sub('[^a-zA-Z0-9]+\\s*', ' ', text) #not a number or a letter\n",
    "        text = text.lower() #lowercase\n",
    "        news_per_day.append(text)\n",
    "\n",
    "    news_cleaned.append(news_per_day)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    news_lemmatized = []\n",
    "\n",
    "    news_per_day = []\n",
    "    for text in news_cleaned[0]:\n",
    "        text = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)]\n",
    "        text = [''.join(lemma) for lemma in text]\n",
    "        text = ' '.join(text)\n",
    "        news_per_day.append(text)\n",
    "\n",
    "    news_lemmatized.append(news_per_day)\n",
    "\n",
    "    stopwords_ = stopwords.words('english')\n",
    "    news_cleaned = []\n",
    "    news_per_day = []\n",
    "    for text in news_lemmatized[0]:\n",
    "        text = [word for word in text.split(' ') if word not in stopwords_]\n",
    "        text = ' '.join(text)\n",
    "        news_per_day.append(text)\n",
    "\n",
    "    news_cleaned.append(news_per_day)\n",
    "\n",
    "    return news_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_cleaned = clean_data_single_prediction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_index = []\n",
    "news_index = []\n",
    "word_index = []\n",
    "corpus = []\n",
    "tickers_index = []\n",
    "dates = df.reset_index()['index']\n",
    "for i, day in enumerate(news_cleaned): #news_cleaned\n",
    "    for j, news in enumerate(day):\n",
    "        for k, text in enumerate(news.split(' ')):\n",
    "            day_index.append(dates[0])\n",
    "            tickers_index.append(ticker)\n",
    "            news_index.append(j)\n",
    "            word_index.append(k)\n",
    "            corpus.append(news.split(' ')[k])\n",
    "\n",
    "tuples = list(zip(day_index, tickers_index, news_index, word_index))\n",
    "multindex = pd.MultiIndex.from_tuples(tuples, names = [\"day\", \"ticker\", \"news\", \"word_count\"])\n",
    "long_news = pd.DataFrame({'word': corpus}, index = multindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_lm(long_news):\n",
    "    lm = pd.read_csv('dictionaries/lm.csv')\n",
    "    lm_sentiment = pd.merge(long_news, lm, how = 'left').set_index(long_news.index)\n",
    "    lm_sentiment = pd.DataFrame(lm_sentiment.groupby(['day', 'ticker', 'news'])['binary_score'].mean())\n",
    "    lm_sentiment = lm_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'binary_score', columns = 'news')\n",
    "    lm_sentiment.columns = [f'sentiment_{index}' for index in lm_sentiment.columns]\n",
    "    \n",
    "    return lm_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_oliveira(long_news):\n",
    "    oliveira = pd.read_csv('dictionaries/oliveira.csv')\n",
    "    ol_sentiment = pd.merge(long_news, oliveira, how = 'left').set_index(long_news.index)\n",
    "    ol_sentiment = pd.DataFrame(ol_sentiment.groupby(['day', 'ticker', 'news'])['score'].mean())\n",
    "    ol_sentiment = ol_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'score', columns = 'news')\n",
    "    ol_sentiment.columns = [f'sentiment_{index}' for index in ol_sentiment.columns]\n",
    "    \n",
    "    return ol_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_sentic(long_news):\n",
    "    sentic = pd.read_csv('dictionaries/sentic.csv')\n",
    "    sen_sentiment = pd.merge(long_news, sentic, \n",
    "                         how = 'left')[['word', 'polarity_intensity']].set_index(long_news.index)\n",
    "    sen_sentiment = pd.DataFrame(sen_sentiment.groupby(['day', 'ticker', 'news'])['polarity_intensity'].mean())\n",
    "    sen_sentiment = sen_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'polarity_intensity', columns = 'news')\n",
    "    sen_sentiment.columns = [f'sentiment_{index}' for index in sen_sentiment.columns]\n",
    "    \n",
    "    return sen_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(sentiment_table, min_news = 0, max_news = 40):\n",
    "    sentiment_table = sentiment_table.dropna(axis = 0, thresh = min_news).iloc[:, : max_news]\n",
    "    impute_values = sentiment_table.mean(axis = 1)\n",
    "    for i in range(len(sentiment_table)):\n",
    "        sentiment_table.iloc[i, :].fillna(impute_values[i], inplace = True)\n",
    "        \n",
    "    return sentiment_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sentiment(sentiment_df, scaler):\n",
    "    scaled = pd.DataFrame(scaler.transform(imputer(sentiment_df)),\n",
    "                          columns = imputer(sentiment_df).columns,\n",
    "                          index = imputer(sentiment_df).index)\n",
    "    \n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_lm = pickle.load(open('scalers/scaler_lm.sav', 'rb'))\n",
    "scaler_ol = pickle.load(open('scalers/scaler_ol.sav', 'rb'))\n",
    "scaler_sen = pickle.load(open('scalers/scaler_sen.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_sentiment = get_sentiment_oliveira(long_news)\n",
    "lm_sentiment = get_sentiment_lm(long_news)\n",
    "sen_sentiment = get_sentiment_sentic(long_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ol_sentiment.shape[1], 41):\n",
    "    ol_sentiment[f'sentiment_{i}'] = np.NaN\n",
    "\n",
    "for i in range(lm_sentiment.shape[1], 41):\n",
    "    lm_sentiment[f'sentiment_{i}'] = np.NaN\n",
    "\n",
    "for i in range(sen_sentiment.shape[1], 41):\n",
    "    sen_sentiment[f'sentiment_{i}'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentiment_0</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>sentiment_3</th>\n",
       "      <th>sentiment_4</th>\n",
       "      <th>sentiment_5</th>\n",
       "      <th>sentiment_6</th>\n",
       "      <th>sentiment_7</th>\n",
       "      <th>sentiment_8</th>\n",
       "      <th>sentiment_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_31</th>\n",
       "      <th>sentiment_32</th>\n",
       "      <th>sentiment_33</th>\n",
       "      <th>sentiment_34</th>\n",
       "      <th>sentiment_35</th>\n",
       "      <th>sentiment_36</th>\n",
       "      <th>sentiment_37</th>\n",
       "      <th>sentiment_38</th>\n",
       "      <th>sentiment_39</th>\n",
       "      <th>sentiment_40</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.2356</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentiment_0  sentiment_1  sentiment_2  sentiment_3  \\\n",
       "day        ticker                                                       \n",
       "2022-03-30 AAPL        -0.2356        0.442        0.384        0.247   \n",
       "\n",
       "                   sentiment_4  sentiment_5  sentiment_6  sentiment_7  \\\n",
       "day        ticker                                                       \n",
       "2022-03-30 AAPL         0.4455       0.0775        0.527        0.296   \n",
       "\n",
       "                   sentiment_8  sentiment_9  ...  sentiment_31  sentiment_32  \\\n",
       "day        ticker                            ...                               \n",
       "2022-03-30 AAPL          0.855       0.1645  ...           NaN           NaN   \n",
       "\n",
       "                   sentiment_33  sentiment_34  sentiment_35  sentiment_36  \\\n",
       "day        ticker                                                           \n",
       "2022-03-30 AAPL             NaN           NaN           NaN           NaN   \n",
       "\n",
       "                   sentiment_37  sentiment_38  sentiment_39  sentiment_40  \n",
       "day        ticker                                                          \n",
       "2022-03-30 AAPL             NaN           NaN           NaN           NaN  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_scaled = imputer(ol_sentiment, min_news = 1, max_news = 40)\n",
    "ol_scaled = scale_sentiment(ol_scaled, scaler_ol)\n",
    "\n",
    "lm_scaled = imputer(lm_sentiment, min_news = 1, max_news = 40)\n",
    "lm_scaled = scale_sentiment(lm_scaled, scaler_lm)\n",
    "\n",
    "sen_scaled = imputer(sen_sentiment, min_news = 1, max_news = 40)\n",
    "sen_scaled = scale_sentiment(sen_scaled, scaler_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_index(arr1, arr2, arr3):\n",
    "    # Converting the arrays into sets\n",
    "    s1 = set(arr1)\n",
    "    s2 = set(arr2)\n",
    "    s3 = set(arr3)\n",
    "      \n",
    "    # Calculates intersection of \n",
    "    # sets on s1 and s2\n",
    "    set1 = s1.intersection(s2)\n",
    "      \n",
    "    # Calculates intersection of sets\n",
    "    # on set1 and s3\n",
    "    result_set = set1.intersection(s3)\n",
    "      \n",
    "    # Converts resulting set to list\n",
    "    final_list = list(result_set)\n",
    "    return final_list\n",
    "def combine_sentiments(sentiment1, sentiment2, sentiment3):\n",
    "    #common indices\n",
    "    indices = intersection_index(ol_scaled.index, sen_scaled.index, lm_scaled.index)\n",
    "    indices = pd.MultiIndex.from_tuples(indices, names = [\"day\", \"ticker\"])\n",
    "    #empty frame\n",
    "    final_sentiment = pd.DataFrame(index = indices, columns = ol_scaled.columns)\n",
    "    \n",
    "    #fulfilling the frame\n",
    "    final_sentiment = pd.DataFrame(index = indices, columns = ol_scaled.columns)\n",
    "    for index in indices:\n",
    "        for column in ol_scaled.columns:\n",
    "            sent_value = 0.4 * ol_scaled.loc[index, column] +  0.2 * lm_scaled.loc[index, column] + 0.4 * sen_scaled.loc[index, column]\n",
    "            \n",
    "            final_sentiment.loc[index, column] = sent_value\n",
    "            \n",
    "    return final_sentiment\n",
    "\n",
    "final_sentiment = combine_sentiments(ol_scaled, lm_scaled, sen_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = Nmf.load('nmf')\n",
    "dictionary = Dictionary.load('dictionary_nmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_corpus = [dictionary.doc2bow(text.split()) for text in news_cleaned[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for i in range(len(other_corpus)):\n",
    "    topics.append(nmf.get_document_topics(other_corpus[i]))\n",
    "topics = reduce(lambda x, y: x + y, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_sorted = sorted(topics, key = lambda x:x[1], reverse = True)[:5]\n",
    "topics_final = [x[0] for x in topics_sorted]\n",
    "topics_final = pd.DataFrame(topics_final, index = [f'topic_{i}' for i in range(5)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = df[[col for col in df.columns if 'news' not in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['target_3_days_previous'] = get_target(historical_data, predict_trend=False).target.rolling(3, closed = 'left').mean()[-1]\n",
    "financials['target_5_days_previous'] = get_target(historical_data, predict_trend=False).target.rolling(5, closed = 'left').mean()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_for_prediction = pd.concat([financials.reset_index(drop = True), final_sentiment.reset_index(drop = True), \n",
    "topics_final.reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 57)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_for_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = pickle.load(open('binary_model.sav', 'rb'))\n",
    "threshold = 0.36448651000920534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(final_data_for_prediction)[::, 1] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(ticker, company_name):\n",
    "    #get news\n",
    "    data = {}\n",
    "    tickers = [ticker]\n",
    "    for ticker in tickers:\n",
    "        start = time.time()\n",
    "        data[ticker] = get_company_news(ticker)\n",
    "        end = time.time() - start\n",
    "        print(f'{ticker} news is parsed!')\n",
    "        #print(f'Sleeping for {np.round((62 - end), 0)} seconds...')\n",
    "        #time.sleep((60 - end))\n",
    "        if ticker != tickers[-1]:\n",
    "            time.sleep(70)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    #historical data\n",
    "    news_filtered = get_news_dataset(ticker, company_name)\n",
    "    historical_data = stock_info.get_data(ticker,\n",
    "                                        start_date = pd.to_datetime(news_filtered['datetime'][0]) - \n",
    "                                        pd.DateOffset(days = 100), \n",
    "                                        end_date =  news_filtered['datetime'].to_list()[-1],\n",
    "                                        index_as_date = False, \n",
    "                                        interval = '1d')\n",
    "    #news + financials\n",
    "    df = get_single_prediction_data()\n",
    "\n",
    "    #sentiment data\n",
    "    news = df[[col for col in df.columns if col.startswith('news')]]\n",
    "    news = news.values.tolist()[0]\n",
    "\n",
    "    #cleaned news\n",
    "    news_cleaned = clean_data_single_prediction(df)\n",
    "\n",
    "    #long news\n",
    "    day_index = []\n",
    "    news_index = []\n",
    "    word_index = []\n",
    "    corpus = []\n",
    "    tickers_index = []\n",
    "    dates = df.reset_index()['index']\n",
    "    for i, day in enumerate(news_cleaned): #news_cleaned\n",
    "        for j, news in enumerate(day):\n",
    "            for k, text in enumerate(news.split(' ')):\n",
    "                day_index.append(dates[0])\n",
    "                tickers_index.append(ticker)\n",
    "                news_index.append(j)\n",
    "                word_index.append(k)\n",
    "                corpus.append(news.split(' ')[k])\n",
    "\n",
    "    tuples = list(zip(day_index, tickers_index, news_index, word_index))\n",
    "    multindex = pd.MultiIndex.from_tuples(tuples, names = [\"day\", \"ticker\", \"news\", \"word_count\"])\n",
    "    long_news = pd.DataFrame({'word': corpus}, index = multindex)\n",
    "    \n",
    "\n",
    "    #getting sentiments\n",
    "    scaler_lm = pickle.load(open('scalers/scaler_lm.sav', 'rb'))\n",
    "    scaler_ol = pickle.load(open('scalers/scaler_ol.sav', 'rb'))\n",
    "    scaler_sen = pickle.load(open('scalers/scaler_sen.sav', 'rb'))\n",
    "    ol_sentiment = get_sentiment_oliveira(long_news)\n",
    "    lm_sentiment = get_sentiment_lm(long_news)\n",
    "    sen_sentiment = get_sentiment_sentic(long_news)\n",
    "    for i in range(ol_sentiment.shape[1], 41):\n",
    "        ol_sentiment[f'sentiment_{i}'] = np.NaN\n",
    "\n",
    "    for i in range(lm_sentiment.shape[1], 41):\n",
    "        lm_sentiment[f'sentiment_{i}'] = np.NaN\n",
    "\n",
    "    for i in range(sen_sentiment.shape[1], 41):\n",
    "        sen_sentiment[f'sentiment_{i}'] = np.NaN\n",
    "\n",
    "    #scaling sentiments\n",
    "    ol_scaled = imputer(ol_sentiment, min_news = 1, max_news = 40)\n",
    "    ol_scaled = scale_sentiment(ol_scaled, scaler_ol)\n",
    "\n",
    "    lm_scaled = imputer(lm_sentiment, min_news = 1, max_news = 40)\n",
    "    lm_scaled = scale_sentiment(lm_scaled, scaler_lm)\n",
    "\n",
    "    sen_scaled = imputer(sen_sentiment, min_news = 1, max_news = 40)\n",
    "    sen_scaled = scale_sentiment(sen_scaled, scaler_sen)\n",
    "\n",
    "    #combining sentiments\n",
    "    final_sentiment = combine_sentiments(ol_scaled, lm_scaled, sen_scaled)\n",
    "\n",
    "    #topic modelling\n",
    "    nmf = Nmf.load('nmf')\n",
    "    dictionary = Dictionary.load('dictionary_nmf')\n",
    "    other_corpus = [dictionary.doc2bow(text.split()) for text in news_cleaned[0]]\n",
    "    topics = []\n",
    "    for i in range(len(other_corpus)):\n",
    "        topics.append(nmf.get_document_topics(other_corpus[i]))\n",
    "    topics = reduce(lambda x, y: x + y, topics)\n",
    "    topics_sorted = sorted(topics, key = lambda x:x[1], reverse = True)[:5]\n",
    "    topics_final = [x[0] for x in topics_sorted]\n",
    "    topics_final = pd.DataFrame(topics_final, index = [f'topic_{i}' for i in range(5)]).transpose()\n",
    "\n",
    "    #final data\n",
    "    financials = df[[col for col in df.columns if 'news' not in col]]\n",
    "    financials['target_3_days_previous'] = get_target(historical_data, predict_trend=False).target.rolling(3, closed = 'left').mean()[-1]\n",
    "    financials['target_5_days_previous'] = get_target(historical_data, predict_trend=False).target.rolling(5, closed = 'left').mean()[-1]\n",
    "    final_data_for_prediction = pd.concat([financials.reset_index(drop = True), final_sentiment.reset_index(drop = True), \n",
    "    topics_final.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "    return final_data_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL news is parsed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjclose</th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>rsi_6_sma</th>\n",
       "      <th>rsi_6_ema</th>\n",
       "      <th>rsi_12_sma</th>\n",
       "      <th>rsi_24_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_35</th>\n",
       "      <th>sentiment_36</th>\n",
       "      <th>sentiment_37</th>\n",
       "      <th>sentiment_38</th>\n",
       "      <th>sentiment_39</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178.960007</td>\n",
       "      <td>166.808002</td>\n",
       "      <td>163.54</td>\n",
       "      <td>164.610001</td>\n",
       "      <td>167.910566</td>\n",
       "      <td>166.039017</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.388844</td>\n",
       "      <td>75.973223</td>\n",
       "      <td>58.478654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.450112</td>\n",
       "      <td>0.439232</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>0.454195</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     adjclose       ma_10   ma_20       ma_30      ema_12      ema_26  \\\n",
       "0  178.960007  166.808002  163.54  164.610001  167.910566  166.039017   \n",
       "\n",
       "  rsi_6_sma  rsi_6_ema rsi_12_sma rsi_24_sma  ...  sentiment_35  sentiment_36  \\\n",
       "0     100.0  88.388844  75.973223  58.478654  ...        0.4823      0.450112   \n",
       "\n",
       "  sentiment_37 sentiment_38 sentiment_39 topic_0 topic_1 topic_2 topic_3  \\\n",
       "0     0.439232     0.426077     0.454195       6       1       0       6   \n",
       "\n",
       "  topic_4  \n",
       "0       1  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_data('AAPL', 'Apple')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f360841077bedc85f6e1678552164e2bbcbbce06b33ab653ea86b15ff9f1e12"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
