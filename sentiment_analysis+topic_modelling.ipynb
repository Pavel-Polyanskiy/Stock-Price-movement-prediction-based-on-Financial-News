{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "biblical-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-click",
   "metadata": {},
   "source": [
    "###  The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "based-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/data_error_list.csv', index_col = 'Unnamed: 0')\n",
    "df2 = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/data50_new.csv', index_col = 'Unnamed: 0')\n",
    "df3 = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/data75.csv', index_col = 'Unnamed: 0')\n",
    "df4 = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/data100.csv', index_col = 'Unnamed: 0')\n",
    "df5 = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/data25.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "informational-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Data/sp100.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "careful-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, sp_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "threaded-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "retired-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26491, 105)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dynamic-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['market_return', 'market_3_days_previous', 'market_5_days_previous'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "duplicate-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "brave-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['index', 'ticker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-howard",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "consolidated-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "oliveira = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Dictionaries/stock_lex_Oliveira.csv')\n",
    "lm = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Dictionaries/LM/LM-SA-2020.csv')\n",
    "sentic = pd.read_csv('/Users/polyanaboss/Desktop/Term paper/Dictionaries/senticnet/senticnet.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "arctic-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('nan', inplace = True)\n",
    "df = df.replace('nan', np.NaN).dropna(how = 'all', axis = 0)\n",
    "df.fillna('nan', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "greek-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting only textual data\n",
    "news = df[[col for col in df.columns if col.startswith('news')]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "guided-paintball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PEP', 'SBUX', 'PCAR', 'PEP', 'REGN', 'SWKS', 'SBUX', 'SNPS', 'TMUS',\n",
       "       'WBA',\n",
       "       ...\n",
       "       'VZ', 'DIS', 'F', 'IBM', 'MA', 'MRK', 'PFE', 'T', 'UPS', 'WFC'],\n",
       "      dtype='object', name='ticker', length=26491)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-tuning",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-verse",
   "metadata": {},
   "source": [
    "### Cleaning from NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "collective-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(news_list):\n",
    "    news_no_na = []\n",
    "    for i in news_list:\n",
    "        i = [el for el in i if el != 'nan']\n",
    "        news_no_na.append(i)\n",
    "        \n",
    "    return news_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "operating-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_no_na = remove_nan(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-eugene",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "hydraulic-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_news(news_list):\n",
    "    news_cleaned = []\n",
    "    for news in news_list:\n",
    "        news_per_day = []\n",
    "        for text in news:\n",
    "            text = re.sub('[^a-zA-Z0-9]+\\s*', ' ', text) #not a number or a letter\n",
    "            text = text.lower() #lowercase\n",
    "            news_per_day.append(text)\n",
    "        \n",
    "        news_cleaned.append(news_per_day)\n",
    "    \n",
    "    return news_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "premier-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_cleaned = clean_news(news_no_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-whale",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "sudden-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ruled-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_news(news_list):\n",
    "    news_lemmatized = []\n",
    "    for news in news_list:\n",
    "        news_per_day = []\n",
    "        for text in news:\n",
    "            text = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)]\n",
    "            text = [''.join(lemma) for lemma in text]\n",
    "            text = ' '.join(text)\n",
    "            news_per_day.append(text)\n",
    "\n",
    "        news_lemmatized.append(news_per_day)\n",
    "        \n",
    "    return news_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "recognized-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_lemmatized = lemmatize_news(news_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-appendix",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "unlikely-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "greenhouse-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(news_list):\n",
    "    news_cleaned = []\n",
    "    for news in news_list:\n",
    "        news_per_day = []\n",
    "        for text in news:\n",
    "            text = [word for word in text.split(' ') if word not in stopwords]\n",
    "            text = ' '.join(text)\n",
    "            news_per_day.append(text)\n",
    "        \n",
    "        news_cleaned.append(news_per_day)\n",
    "    \n",
    "    return news_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "sublime-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_cleaned = remove_stopwords(news_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-pacific",
   "metadata": {},
   "source": [
    "### Dictionaries preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-anime",
   "metadata": {},
   "source": [
    "#### Senticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "muslim-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>polarity_value</th>\n",
       "      <th>polarity_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon_theater</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned_airstrip</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandoned_farmland</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              concept polarity_value  polarity_intensity\n",
       "0             abandon       negative              -0.391\n",
       "1     abandon_theater       negative              -0.823\n",
       "2           abandoned       negative              -0.458\n",
       "3  abandoned_airstrip       negative              -0.771\n",
       "4  abandoned_farmland       negative              -0.201"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentic = sentic[['CONCEPT', 'POLARITY VALUE', 'POLARITY INTENSITY']]\n",
    "sentic.columns = ['CONCEPT', 'POLARITY_VALUE', 'POLARITY_INTENSITY']\n",
    "sentic.columns = [head.lower() for head in sentic.columns]\n",
    "sentic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "professional-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentic(concept):\n",
    "    try:\n",
    "        concept = re.sub('_', ' ', concept)\n",
    "    except:\n",
    "        concept = concept\n",
    "    return concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "above-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentic.concept = sentic.concept.apply(lambda concept: split_sentic(concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "protecting-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentic.rename(columns = {'concept': 'word'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-terror",
   "metadata": {},
   "source": [
    "#### Loughran-McDonald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "attached-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.word = lm.word.apply(lambda concept: split_sentic(concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "reserved-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = lm[(lm['sentiment'] == 'Negative') | (lm['sentiment'] == 'Positive')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "photographic-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm['binary_score'] = lm['sentiment'].apply(lambda sent: 1 if sent == 'Positive' else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "equivalent-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pd.DataFrame(lm.groupby('word')['binary_score'].mean()).sort_values('word').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-dover",
   "metadata": {},
   "source": [
    "#### Oliveira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "vocational-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "oliveira = oliveira[['Item', 'Aff_Score']]\n",
    "oliveira.columns = ['word', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "western-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "oliveira.drop_duplicates('word', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-journalism",
   "metadata": {},
   "source": [
    "### Long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "later-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df.reset_index()['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "consistent-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_index = []\n",
    "news_index = []\n",
    "word_index = []\n",
    "corpus = []\n",
    "tickers_index = []\n",
    "dates = df.reset_index()['index']\n",
    "for i, day in enumerate(news_cleaned): #news_cleaned\n",
    "    for j, news in enumerate(day):\n",
    "        for k, text in enumerate(news.split(' ')):\n",
    "            day_index.append(dates[i])\n",
    "            tickers_index.append(tickers[i])\n",
    "            news_index.append(j)\n",
    "            word_index.append(k)\n",
    "            corpus.append(news.split(' ')[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "experimental-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(zip(day_index, tickers_index, news_index, word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "hindu-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "multindex = pd.MultiIndex.from_tuples(tuples, names = [\"day\", \"ticker\", \"news\", \"word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "induced-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_news = pd.DataFrame({'word': corpus}, index = multindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "deluxe-boutique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th>news</th>\n",
       "      <th>word_count</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-03-08</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">PEP</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>est</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  word\n",
       "day        ticker news word_count     \n",
       "2021-03-08 PEP    0    0           mar\n",
       "                       1           est\n",
       "                       2            ce\n",
       "                       3            un\n",
       "                       4           bon"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-bumper",
   "metadata": {},
   "source": [
    "### Loughran-McDonald sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "divine-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_lm(long_news):\n",
    "    lm_sentiment = pd.merge(long_news, lm, how = 'left').set_index(long_news.index)\n",
    "    lm_sentiment = pd.DataFrame(lm_sentiment.groupby(['day', 'ticker', 'news'])['binary_score'].mean())\n",
    "    lm_sentiment = lm_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'binary_score', columns = 'news')\n",
    "    lm_sentiment.columns = [f'sentiment_{index}' for index in lm_sentiment.columns]\n",
    "    \n",
    "    return lm_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "headed-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_sentiment = get_sentiment_lm(long_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-michigan",
   "metadata": {},
   "source": [
    "### Oliveira Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "centered-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_oliveira(long_news):\n",
    "    ol_sentiment = pd.merge(long_news, oliveira, how = 'left').set_index(long_news.index)\n",
    "    ol_sentiment = pd.DataFrame(ol_sentiment.groupby(['day', 'ticker', 'news'])['score'].mean())\n",
    "    ol_sentiment = ol_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'score', columns = 'news')\n",
    "    ol_sentiment.columns = [f'sentiment_{index}' for index in ol_sentiment.columns]\n",
    "    \n",
    "    return ol_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bigger-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_sentiment = get_sentiment_oliveira(long_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-tender",
   "metadata": {},
   "source": [
    "### Sentic Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "integral-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_sentic(long_news):\n",
    "    sen_sentiment = pd.merge(long_news, sentic, \n",
    "                         how = 'left')[['word', 'polarity_intensity']].set_index(long_news.index)\n",
    "    sen_sentiment = pd.DataFrame(sen_sentiment.groupby(['day', 'ticker', 'news'])['polarity_intensity'].mean())\n",
    "    sen_sentiment = sen_sentiment.reset_index().pivot(index = ['day', 'ticker'], \n",
    "                                                values = 'polarity_intensity', columns = 'news')\n",
    "    sen_sentiment.columns = [f'sentiment_{index}' for index in sen_sentiment.columns]\n",
    "    \n",
    "    return sen_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "excess-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_sentiment = get_sentiment_sentic(long_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "pointed-liabilities",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_shapes():\n",
    "    if sen_sentiment.shape == ol_sentiment.shape and sen_sentiment.shape == lm_sentiment.shape:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "check_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-sustainability",
   "metadata": {},
   "source": [
    "### Imputing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "stretch-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(sentiment_table, min_news = 20, max_news = 60):\n",
    "    sentiment_table = sentiment_table.dropna(axis = 0, thresh = min_news).iloc[:, : max_news]\n",
    "    impute_values = sentiment_table.mean(axis = 1)\n",
    "    for i in range(len(sentiment_table)):\n",
    "        sentiment_table.iloc[i, :].fillna(impute_values[i], inplace = True)\n",
    "        \n",
    "    return sentiment_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-buffer",
   "metadata": {},
   "source": [
    "### Scaling sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "photographic-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sentiment(sentiment_df):\n",
    "    scaler = MinMaxScaler(feature_range = [0, 1])\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(imputer(sentiment_df)),\n",
    "                          columns = imputer(sentiment_df).columns,\n",
    "                          index = imputer(sentiment_df).index)\n",
    "    \n",
    "    return scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "solar-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_scaled = imputer(ol_sentiment, min_news = 5, max_news = 40)\n",
    "ol_scaled, scaler_ol = scale_sentiment(ol_scaled)\n",
    "\n",
    "lm_scaled = imputer(lm_sentiment, min_news = 5, max_news = 40)\n",
    "lm_scaled, scaler_lm = scale_sentiment(lm_scaled)\n",
    "\n",
    "sen_scaled = imputer(sen_sentiment, min_news = 5, max_news = 40)\n",
    "sen_scaled, scaler_sen = scale_sentiment(sen_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-young",
   "metadata": {},
   "source": [
    "### Combining sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "foreign-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_index(arr1, arr2, arr3):\n",
    "    # Converting the arrays into sets\n",
    "    s1 = set(arr1)\n",
    "    s2 = set(arr2)\n",
    "    s3 = set(arr3)\n",
    "      \n",
    "    # Calculates intersection of \n",
    "    # sets on s1 and s2\n",
    "    set1 = s1.intersection(s2)\n",
    "      \n",
    "    # Calculates intersection of sets\n",
    "    # on set1 and s3\n",
    "    result_set = set1.intersection(s3)\n",
    "      \n",
    "    # Converts resulting set to list\n",
    "    final_list = list(result_set)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "wrapped-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sentiments(sentiment1, sentiment2, sentiment3):\n",
    "    #common indices\n",
    "    indices = intersection_index(ol_scaled.index, sen_scaled.index, lm_scaled.index)\n",
    "    indices = pd.MultiIndex.from_tuples(indices, names = [\"day\", \"ticker\"])\n",
    "    #empty frame\n",
    "    final_sentiment = pd.DataFrame(index = indices, columns = ol_scaled.columns)\n",
    "    \n",
    "    #fulfilling the frame\n",
    "    final_sentiment = pd.DataFrame(index = indices, columns = ol_scaled.columns)\n",
    "    for index in indices:\n",
    "        for column in ol_scaled.columns:\n",
    "            sent_value = 0.4 * ol_scaled.loc[index, column] +  0.2 * lm_scaled.loc[index, column] + 0.4 * sen_scaled.loc[index, column]\n",
    "            \n",
    "            final_sentiment.loc[index, column] = sent_value\n",
    "            \n",
    "    return final_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "blond-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentiment = combine_sentiments(ol_scaled, lm_scaled, sen_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cathedral-soviet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentiment_0</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>sentiment_3</th>\n",
       "      <th>sentiment_4</th>\n",
       "      <th>sentiment_5</th>\n",
       "      <th>sentiment_6</th>\n",
       "      <th>sentiment_7</th>\n",
       "      <th>sentiment_8</th>\n",
       "      <th>sentiment_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_30</th>\n",
       "      <th>sentiment_31</th>\n",
       "      <th>sentiment_32</th>\n",
       "      <th>sentiment_33</th>\n",
       "      <th>sentiment_34</th>\n",
       "      <th>sentiment_35</th>\n",
       "      <th>sentiment_36</th>\n",
       "      <th>sentiment_37</th>\n",
       "      <th>sentiment_38</th>\n",
       "      <th>sentiment_39</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <th>LMT</th>\n",
       "      <td>0.340515</td>\n",
       "      <td>0.291727</td>\n",
       "      <td>0.582527</td>\n",
       "      <td>0.589531</td>\n",
       "      <td>0.707774</td>\n",
       "      <td>0.694412</td>\n",
       "      <td>0.698201</td>\n",
       "      <td>0.583492</td>\n",
       "      <td>0.583731</td>\n",
       "      <td>0.534434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556586</td>\n",
       "      <td>0.542227</td>\n",
       "      <td>0.620985</td>\n",
       "      <td>0.577153</td>\n",
       "      <td>0.574217</td>\n",
       "      <td>0.608536</td>\n",
       "      <td>0.563171</td>\n",
       "      <td>0.56963</td>\n",
       "      <td>0.55342</td>\n",
       "      <td>0.586994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>MRNA</th>\n",
       "      <td>0.377616</td>\n",
       "      <td>0.43792</td>\n",
       "      <td>0.573703</td>\n",
       "      <td>0.581826</td>\n",
       "      <td>0.53217</td>\n",
       "      <td>0.460641</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>0.602061</td>\n",
       "      <td>0.542229</td>\n",
       "      <td>0.68658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533275</td>\n",
       "      <td>0.515325</td>\n",
       "      <td>0.596521</td>\n",
       "      <td>0.549575</td>\n",
       "      <td>0.542081</td>\n",
       "      <td>0.580673</td>\n",
       "      <td>0.539469</td>\n",
       "      <td>0.537797</td>\n",
       "      <td>0.524757</td>\n",
       "      <td>0.557752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.523501</td>\n",
       "      <td>0.56505</td>\n",
       "      <td>0.387739</td>\n",
       "      <td>0.546809</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.609743</td>\n",
       "      <td>0.619085</td>\n",
       "      <td>0.57864</td>\n",
       "      <td>0.575597</td>\n",
       "      <td>0.52947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545689</td>\n",
       "      <td>0.520244</td>\n",
       "      <td>0.604682</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.538651</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.549925</td>\n",
       "      <td>0.533894</td>\n",
       "      <td>0.524763</td>\n",
       "      <td>0.55481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <th>TGT</th>\n",
       "      <td>0.440419</td>\n",
       "      <td>0.552679</td>\n",
       "      <td>0.530801</td>\n",
       "      <td>0.313919</td>\n",
       "      <td>0.601868</td>\n",
       "      <td>0.470906</td>\n",
       "      <td>0.482044</td>\n",
       "      <td>0.507302</td>\n",
       "      <td>0.502833</td>\n",
       "      <td>0.457532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469926</td>\n",
       "      <td>0.442862</td>\n",
       "      <td>0.524441</td>\n",
       "      <td>0.46874</td>\n",
       "      <td>0.464423</td>\n",
       "      <td>0.500213</td>\n",
       "      <td>0.47154</td>\n",
       "      <td>0.457437</td>\n",
       "      <td>0.443932</td>\n",
       "      <td>0.46999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.647576</td>\n",
       "      <td>0.491208</td>\n",
       "      <td>0.465238</td>\n",
       "      <td>0.466653</td>\n",
       "      <td>0.587661</td>\n",
       "      <td>0.497265</td>\n",
       "      <td>0.506391</td>\n",
       "      <td>0.696608</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.412798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50067</td>\n",
       "      <td>0.476108</td>\n",
       "      <td>0.558808</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.497388</td>\n",
       "      <td>0.536829</td>\n",
       "      <td>0.504299</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.480297</td>\n",
       "      <td>0.509414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentiment_0 sentiment_1 sentiment_2 sentiment_3 sentiment_4  \\\n",
       "day        ticker                                                               \n",
       "2021-09-24 LMT       0.340515    0.291727    0.582527    0.589531    0.707774   \n",
       "2022-01-05 MRNA      0.377616     0.43792    0.573703    0.581826     0.53217   \n",
       "2021-11-30 CSCO      0.523501     0.56505    0.387739    0.546809      0.6504   \n",
       "2021-06-22 TGT       0.440419    0.552679    0.530801    0.313919    0.601868   \n",
       "2021-06-11 TSLA      0.647576    0.491208    0.465238    0.466653    0.587661   \n",
       "\n",
       "                  sentiment_5 sentiment_6 sentiment_7 sentiment_8 sentiment_9  \\\n",
       "day        ticker                                                               \n",
       "2021-09-24 LMT       0.694412    0.698201    0.583492    0.583731    0.534434   \n",
       "2022-01-05 MRNA      0.460641    0.716266    0.602061    0.542229     0.68658   \n",
       "2021-11-30 CSCO      0.609743    0.619085     0.57864    0.575597     0.52947   \n",
       "2021-06-22 TGT       0.470906    0.482044    0.507302    0.502833    0.457532   \n",
       "2021-06-11 TSLA      0.497265    0.506391    0.696608    0.532438    0.412798   \n",
       "\n",
       "                   ... sentiment_30 sentiment_31 sentiment_32 sentiment_33  \\\n",
       "day        ticker  ...                                                       \n",
       "2021-09-24 LMT     ...     0.556586     0.542227     0.620985     0.577153   \n",
       "2022-01-05 MRNA    ...     0.533275     0.515325     0.596521     0.549575   \n",
       "2021-11-30 CSCO    ...     0.545689     0.520244     0.604682     0.550966   \n",
       "2021-06-22 TGT     ...     0.469926     0.442862     0.524441      0.46874   \n",
       "2021-06-11 TSLA    ...      0.50067     0.476108     0.558808     0.505691   \n",
       "\n",
       "                  sentiment_34 sentiment_35 sentiment_36 sentiment_37  \\\n",
       "day        ticker                                                       \n",
       "2021-09-24 LMT        0.574217     0.608536     0.563171      0.56963   \n",
       "2022-01-05 MRNA       0.542081     0.580673     0.539469     0.537797   \n",
       "2021-11-30 CSCO       0.538651     0.581818     0.549925     0.533894   \n",
       "2021-06-22 TGT        0.464423     0.500213      0.47154     0.457437   \n",
       "2021-06-11 TSLA       0.497388     0.536829     0.504299     0.491876   \n",
       "\n",
       "                  sentiment_38 sentiment_39  \n",
       "day        ticker                            \n",
       "2021-09-24 LMT         0.55342     0.586994  \n",
       "2022-01-05 MRNA       0.524757     0.557752  \n",
       "2021-11-30 CSCO       0.524763      0.55481  \n",
       "2021-06-22 TGT        0.443932      0.46999  \n",
       "2021-06-11 TSLA       0.480297     0.509414  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "infrared-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4477, 40)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-petroleum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lined-hawaiian",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "attempted-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_index = []\n",
    "news_index = []\n",
    "corpus = []\n",
    "tickers_index = []\n",
    "for i, day in enumerate(news_cleaned): #news_cleaned\n",
    "    for j, news in enumerate(day):\n",
    "            day_index.append(dates[i])\n",
    "            tickers_index.append(tickers[i])\n",
    "            news_index.append(j)\n",
    "            corpus.append(news)\n",
    "\n",
    "\n",
    "\n",
    "tuples = list(zip(day_index, tickers_index, news_index))\n",
    "\n",
    "multindex = pd.MultiIndex.from_tuples(tuples, names = [\"day\", \"ticker\", \"news\"])\n",
    "\n",
    "news_cleaned_df = pd.DataFrame({'text': corpus}, index = multindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "rocky-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th>news</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2021-03-08</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">PEP</th>\n",
       "      <th>0</th>\n",
       "      <td>mar est ce un bon mois pour acheter de action ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e marzo un buen para comprar acciones de pepsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marzo un buon mese per acquistare azioni pepsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maart een goede maand om pepsico aandelen te k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>0</th>\n",
       "      <td>paccar inc stock fall monday underperforms market</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     text\n",
       "day        ticker news                                                   \n",
       "2021-03-08 PEP    0     mar est ce un bon mois pour acheter de action ...\n",
       "                  1     e marzo un buen para comprar acciones de pepsi...\n",
       "                  2     marzo un buon mese per acquistare azioni pepsi...\n",
       "                  3     maart een goede maand om pepsico aandelen te k...\n",
       "2021-03-09 PCAR   0     paccar inc stock fall monday underperforms market"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "numerous-novel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103814, 1)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "stock-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = news_cleaned_df.text.apply(lambda text: text.split(' '))\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "dictionary.filter_extremes(\n",
    "    no_below = 3,\n",
    "    no_above = 0.85\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "greatest-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicModelling():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_texts(self):\n",
    "        texts = news_cleaned_df.text.apply(lambda text: text.split(' '))\n",
    "        return texts\n",
    "    \n",
    "    #dictionary\n",
    "    def get_dictionary(self):\n",
    "        texts = self.get_texts()\n",
    "        dictionary = Dictionary(texts)\n",
    "        #filtering dict\n",
    "        dictionary.filter_extremes(\n",
    "        no_below = 3,\n",
    "        no_above = 0.85\n",
    "        )\n",
    "        return dictionary\n",
    "    \n",
    "    #corpus from dictionary\n",
    "    def get_corpus(self):\n",
    "        corpus = [self.get_dictionary().doc2bow(text) for text in texts]\n",
    "        return corpus\n",
    "    \n",
    "    #NMF\n",
    "    def NMF(self, min_n = 2, max_n = 30):\n",
    "        topics = range(min_n, max_n + 1, 2)\n",
    "        scores_nmf = {}\n",
    "        for i in topics:\n",
    "            nmf = Nmf(corpus, i, chunksize = 100)\n",
    "            coherence = CoherenceModel(model = nmf, texts = self.get_texts(), \n",
    "                                         dictionary = self.get_dictionary(), coherence='c_v').get_coherence()\n",
    "            scores_nmf[i] = coherence\n",
    "        return scores_nmf\n",
    "    \n",
    "    #LDA\n",
    "    def LDA(self, min_n = 2, max_n = 30):\n",
    "        topics = range(min_n, max_n + 1, 2)\n",
    "        scores_lda = {}\n",
    "        for i in topics:\n",
    "            nmf = LdaMulticore(corpus, i, chunksize = 100)\n",
    "            coherence = CoherenceModel(model = nmf, texts = self.get_texts(), \n",
    "                                         dictionary = self.get_dictionary(), coherence='c_v').get_coherence()\n",
    "            scores_lda[i] = coherence\n",
    "        return scores_lda\n",
    "    \n",
    "    #LSI\n",
    "    def LSI(self, min_n = 2, max_n = 30):\n",
    "        topics = range(min_n, max_n + 1, 2)\n",
    "        scores_lsi = {}\n",
    "        for i in topics:\n",
    "            lsi = models.lsimodel.LsiModel(corpus, i, chunksize = 100)\n",
    "            coherence = CoherenceModel(model = lsi, texts = self.get_texts(), \n",
    "                                         dictionary = self.get_dictionary(), coherence='c_v').get_coherence()\n",
    "            scores_lsi[i] = coherence\n",
    "        return scores_lsi\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-processor",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "hourly-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = Nmf(corpus, num_topics = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdp_model = models.hdpmodel.HdpModel(corpus, id2word = dictionary, T = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoherenceModel(model = hdp_model, texts = texts, \n",
    "                                         dictionary = common_dictionary, coherence='c_v').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "incorrect-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621356725724845"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CoherenceModel(model = nmf, texts = texts, \n",
    "                                         dictionary = dictionary, coherence='c_v').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "paperback-youth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_words_tuples = nmf.print_topics(num_words=5)\n",
    "top_words_dict = {}\n",
    "for tup in top_words_tuples:\n",
    "    word_indices = [int(n) for n in re.findall('\"([^\"]*)\"', tup[1])]\n",
    "    words = [dictionary[n] for n in word_indices]\n",
    "    word_weights = [float(n) for n in re.findall(\"\\d+\\.\\d+\", tup[1])]\n",
    "    top_words_dict[tup[0]] = list(map(list, list(zip(words, word_weights))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cognitive-steering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_0</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[skyworks, 0.061]</td>\n",
       "      <td>[rejected, 0.049]</td>\n",
       "      <td>[june, 0.042]</td>\n",
       "      <td>[17, 0.04]</td>\n",
       "      <td>[recovery, 0.029]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[agrees, 0.038]</td>\n",
       "      <td>[regn, 0.028]</td>\n",
       "      <td>[anticipate, 0.028]</td>\n",
       "      <td>[200, 0.026]</td>\n",
       "      <td>[already, 0.025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[still, 0.028]</td>\n",
       "      <td>[walgreens, 0.017]</td>\n",
       "      <td>[usage, 0.016]</td>\n",
       "      <td>[perfect, 0.013]</td>\n",
       "      <td>[alliance, 0.013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[covid, 0.28]</td>\n",
       "      <td>[oncology, 0.015]</td>\n",
       "      <td>[111, 0.013]</td>\n",
       "      <td>[thru, 0.011]</td>\n",
       "      <td>[daily, 0.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ad, 0.162]</td>\n",
       "      <td>[successful, 0.028]</td>\n",
       "      <td>[nda, 0.027]</td>\n",
       "      <td>[biggest, 0.027]</td>\n",
       "      <td>[united, 0.025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[targeting, 0.194]</td>\n",
       "      <td>[pinduoduo, 0.017]</td>\n",
       "      <td>[recovery, 0.017]</td>\n",
       "      <td>[skyworks, 0.017]</td>\n",
       "      <td>[rejected, 0.016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[research, 0.076]</td>\n",
       "      <td>[ceo, 0.039]</td>\n",
       "      <td>[move, 0.038]</td>\n",
       "      <td>[financials, 0.027]</td>\n",
       "      <td>[scheme, 0.024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[gilead, 0.1]</td>\n",
       "      <td>[role, 0.098]</td>\n",
       "      <td>[inching, 0.055]</td>\n",
       "      <td>[leading, 0.016]</td>\n",
       "      <td>[post, 0.014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[competitor, 0.155]</td>\n",
       "      <td>[oncology, 0.04]</td>\n",
       "      <td>[daily, 0.016]</td>\n",
       "      <td>[cheaper, 0.015]</td>\n",
       "      <td>[xcel, 0.015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[covid, 0.1]</td>\n",
       "      <td>[trade, 0.072]</td>\n",
       "      <td>[royal, 0.056]</td>\n",
       "      <td>[set, 0.037]</td>\n",
       "      <td>[synopsys, 0.028]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 top_0                top_1                top_2  \\\n",
       "0    [skyworks, 0.061]    [rejected, 0.049]        [june, 0.042]   \n",
       "1      [agrees, 0.038]        [regn, 0.028]  [anticipate, 0.028]   \n",
       "2       [still, 0.028]   [walgreens, 0.017]       [usage, 0.016]   \n",
       "3        [covid, 0.28]    [oncology, 0.015]         [111, 0.013]   \n",
       "4          [ad, 0.162]  [successful, 0.028]         [nda, 0.027]   \n",
       "5   [targeting, 0.194]   [pinduoduo, 0.017]    [recovery, 0.017]   \n",
       "6    [research, 0.076]         [ceo, 0.039]        [move, 0.038]   \n",
       "7        [gilead, 0.1]        [role, 0.098]     [inching, 0.055]   \n",
       "8  [competitor, 0.155]     [oncology, 0.04]       [daily, 0.016]   \n",
       "9         [covid, 0.1]       [trade, 0.072]       [royal, 0.056]   \n",
       "\n",
       "                 top_3              top_4  \n",
       "0           [17, 0.04]  [recovery, 0.029]  \n",
       "1         [200, 0.026]   [already, 0.025]  \n",
       "2     [perfect, 0.013]  [alliance, 0.013]  \n",
       "3        [thru, 0.011]      [daily, 0.01]  \n",
       "4     [biggest, 0.027]    [united, 0.025]  \n",
       "5    [skyworks, 0.017]  [rejected, 0.016]  \n",
       "6  [financials, 0.027]    [scheme, 0.024]  \n",
       "7     [leading, 0.016]      [post, 0.014]  \n",
       "8     [cheaper, 0.015]      [xcel, 0.015]  \n",
       "9         [set, 0.037]  [synopsys, 0.028]  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top_words_dict, index=[f'top_{i}' for i in range(5)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cutting-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_topics(model, news_cleaned_df = news_cleaned_df):\n",
    "    nmf_topics = [model[corpus[i]] for i in range(len(news_cleaned_df))]\n",
    "    news_cleaned_df['nmf_topics'] = nmf_topics\n",
    "    news_cleaned_df.topic = news_cleaned_df.nmf_topics.apply(lambda score: \n",
    "                                 sorted(score, key = lambda x:x[1], reverse = True)[0][0])\n",
    "\n",
    "    news_cleaned_df.nmf_topics = news_cleaned_df.groupby(['day', 'ticker']).agg({'nmf_topics': \n",
    "                                                    lambda x: x})\n",
    "\n",
    "    news_cleaned_df.nmf_topics = news_cleaned_df.nmf_topics.apply(lambda topics:reduce(lambda x, y: x + y, topics))\n",
    "    \n",
    "    \n",
    "    topics_sorted = []\n",
    "    for i in range(len(news_cleaned_df)):\n",
    "        length = len(news_cleaned_df.nmf_topics[i])\n",
    "        if type(news_cleaned_df.nmf_topics[i]) != list:\n",
    "            topics = []\n",
    "            probas = []\n",
    "            for i, value in enumerate(news_cleaned_df.nmf_topics[i]):\n",
    "                if type(value) == int: \n",
    "                    topics.append(value)\n",
    "                else:\n",
    "                    probas.append(value)   \n",
    "            news_cleaned_df.nmf_topics[i] = list(map(tuple, list(zip(topics, probas))))\n",
    "        if length >= 5:\n",
    "            n = sorted(news_cleaned_df.nmf_topics[i], key = lambda x:x[1], reverse = True)[:5]\n",
    "        elif length > 2:\n",
    "            n = sorted(news_cleaned_df.nmf_topics[i], key = lambda x:x[1], reverse = True)\n",
    "        else:\n",
    "            n = news_cleaned_df.nmf_topics[i]\n",
    "\n",
    "        topics_sorted.append(n)\n",
    "        \n",
    "        \n",
    "    topics_distribution = []\n",
    "    for news in topics_sorted:\n",
    "        topics_distr = [topic[0] for topic in news]\n",
    "        topics_distribution.append(topics_distr)\n",
    "        \n",
    "    news_cleaned_df['topics'] = topics_distribution\n",
    "\n",
    "    news_cleaned_df = news_cleaned_df.groupby(['day', 'ticker']).agg({'topics': lambda x: x[0]})\n",
    "\n",
    "    for i in range(len(news_cleaned_df)):\n",
    "        length =  len(news_cleaned_df.topics[i])\n",
    "        topics = news_cleaned_df.topics[i]\n",
    "        if length != 5:\n",
    "            news_cleaned_df.topics[i] = topics + [-1] * (5 - length)\n",
    "\n",
    "    for i in range(5):\n",
    "        news_cleaned_df[f'topic_{i}'] = news_cleaned_df['topics'].apply(lambda x: x[i])\n",
    "        \n",
    "    news_cleaned_df.drop('topics', axis = 1, inplace = True)\n",
    "    \n",
    "    return news_cleaned_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "sufficient-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = distribute_topics(nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fifteen-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-03-04</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMGN</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSS</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIIB</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-03-01</th>\n",
       "      <th>MRK</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPS</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFC</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26334 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topic_0  topic_1  topic_2  topic_3  topic_4\n",
       "day        ticker                                             \n",
       "2021-03-04 AAPL          2        2        2        2        2\n",
       "           AMGN          2        9        2        0        7\n",
       "           AMZN          2        2        2        2        2\n",
       "           ANSS          2        3        6        4        7\n",
       "           BIIB          2        2        1        0        7\n",
       "...                    ...      ...      ...      ...      ...\n",
       "2022-03-01 MRK           0        6        0        9        6\n",
       "           PFE           0        0        0        0        0\n",
       "           T             2        8        6        0        2\n",
       "           UPS           6        2        3        0        1\n",
       "           WFC           7        2        6        9        1\n",
       "\n",
       "[26334 rows x 5 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-shelf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vital-analysis",
   "metadata": {},
   "source": [
    "### Number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "multiple-recording",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.690641113620712,\n",
       " 4: 0.6591180613699776,\n",
       " 6: 0.6468224956128372,\n",
       " 8: 0.6730862973189569,\n",
       " 10: 0.6651128624216931}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicModelling().NMF(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "latin-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7200340789289004\n",
      "0.6766447390767569\n",
      "0.67859995420348\n",
      "0.6979219690809666\n",
      "0.691441548278682\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 11,2):\n",
    "    lsi = models.lsimodel.LsiModel(corpus,num_topics=i)\n",
    "    score = CoherenceModel(model = lsi, texts = texts, \n",
    "                                         dictionary = dictionary, coherence='c_v').get_coherence()\n",
    "    \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-empty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "generic-generation",
   "metadata": {},
   "source": [
    "### Sentiments + Topics + Financial Indicators Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "western-thread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adjclose</th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>rsi_6_sma</th>\n",
       "      <th>rsi_6_ema</th>\n",
       "      <th>rsi_12_sma</th>\n",
       "      <th>rsi_24_sma</th>\n",
       "      <th>target</th>\n",
       "      <th>trend</th>\n",
       "      <th>target_3_days_previous</th>\n",
       "      <th>target_5_days_previous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2021-03-08</th>\n",
       "      <th>PEP</th>\n",
       "      <td>129.404297</td>\n",
       "      <td>127.362002</td>\n",
       "      <td>129.955677</td>\n",
       "      <td>131.571941</td>\n",
       "      <td>128.281940</td>\n",
       "      <td>130.476961</td>\n",
       "      <td>71.375403</td>\n",
       "      <td>44.685097</td>\n",
       "      <td>48.945097</td>\n",
       "      <td>45.900743</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBUX</th>\n",
       "      <td>103.238434</td>\n",
       "      <td>103.153905</td>\n",
       "      <td>103.26861</td>\n",
       "      <td>101.790343</td>\n",
       "      <td>103.378520</td>\n",
       "      <td>102.633260</td>\n",
       "      <td>59.97692</td>\n",
       "      <td>61.102845</td>\n",
       "      <td>52.272718</td>\n",
       "      <td>64.247023</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2021-03-09</th>\n",
       "      <th>PCAR</th>\n",
       "      <td>92.200859</td>\n",
       "      <td>90.472639</td>\n",
       "      <td>92.207153</td>\n",
       "      <td>92.008013</td>\n",
       "      <td>90.990975</td>\n",
       "      <td>90.996424</td>\n",
       "      <td>62.827155</td>\n",
       "      <td>52.03783</td>\n",
       "      <td>45.591027</td>\n",
       "      <td>54.200355</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP</th>\n",
       "      <td>129.521805</td>\n",
       "      <td>127.478115</td>\n",
       "      <td>129.577964</td>\n",
       "      <td>131.396891</td>\n",
       "      <td>128.454613</td>\n",
       "      <td>130.397044</td>\n",
       "      <td>70.658179</td>\n",
       "      <td>53.309848</td>\n",
       "      <td>43.732052</td>\n",
       "      <td>43.823236</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGN</th>\n",
       "      <td>470.630005</td>\n",
       "      <td>456.917001</td>\n",
       "      <td>469.624998</td>\n",
       "      <td>483.584331</td>\n",
       "      <td>461.829836</td>\n",
       "      <td>473.385318</td>\n",
       "      <td>63.941681</td>\n",
       "      <td>47.491796</td>\n",
       "      <td>42.011082</td>\n",
       "      <td>33.531447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adjclose       ma_10       ma_20       ma_30      ema_12  \\\n",
       "day        ticker                                                               \n",
       "2021-03-08 PEP     129.404297  127.362002  129.955677  131.571941  128.281940   \n",
       "           SBUX    103.238434  103.153905   103.26861  101.790343  103.378520   \n",
       "2021-03-09 PCAR     92.200859   90.472639   92.207153   92.008013   90.990975   \n",
       "           PEP     129.521805  127.478115  129.577964  131.396891  128.454613   \n",
       "           REGN    470.630005  456.917001  469.624998  483.584331  461.829836   \n",
       "\n",
       "                       ema_26  rsi_6_sma  rsi_6_ema rsi_12_sma rsi_24_sma  \\\n",
       "day        ticker                                                           \n",
       "2021-03-08 PEP     130.476961  71.375403  44.685097  48.945097  45.900743   \n",
       "           SBUX    102.633260   59.97692  61.102845  52.272718  64.247023   \n",
       "2021-03-09 PCAR     90.996424  62.827155   52.03783  45.591027  54.200355   \n",
       "           PEP     130.397044  70.658179  53.309848  43.732052  43.823236   \n",
       "           REGN    473.385318  63.941681  47.491796  42.011082  33.531447   \n",
       "\n",
       "                   target  trend  target_3_days_previous  \\\n",
       "day        ticker                                          \n",
       "2021-03-08 PEP          0     14                0.333333   \n",
       "           SBUX         0     13                0.000000   \n",
       "2021-03-09 PCAR         0     46                0.000000   \n",
       "           PEP          0     13                0.333333   \n",
       "           REGN         1      1                1.000000   \n",
       "\n",
       "                   target_5_days_previous  \n",
       "day        ticker                          \n",
       "2021-03-08 PEP                        0.2  \n",
       "           SBUX                       0.0  \n",
       "2021-03-09 PCAR                       0.0  \n",
       "           PEP                        0.2  \n",
       "           REGN                       0.6  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials = df[[col for col in df.columns if 'news' not in col]]\n",
    "financials = financials.reset_index().rename(columns = {'index' : 'day'}).set_index(['day', 'ticker'])\n",
    "financials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "racial-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentiment_0</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>sentiment_3</th>\n",
       "      <th>sentiment_4</th>\n",
       "      <th>sentiment_5</th>\n",
       "      <th>sentiment_6</th>\n",
       "      <th>sentiment_7</th>\n",
       "      <th>sentiment_8</th>\n",
       "      <th>sentiment_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_50</th>\n",
       "      <th>sentiment_51</th>\n",
       "      <th>sentiment_52</th>\n",
       "      <th>sentiment_53</th>\n",
       "      <th>sentiment_54</th>\n",
       "      <th>sentiment_55</th>\n",
       "      <th>sentiment_56</th>\n",
       "      <th>sentiment_57</th>\n",
       "      <th>sentiment_58</th>\n",
       "      <th>sentiment_59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.257498</td>\n",
       "      <td>0.408812</td>\n",
       "      <td>0.368385</td>\n",
       "      <td>0.383385</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.505084</td>\n",
       "      <td>0.382462</td>\n",
       "      <td>0.351178</td>\n",
       "      <td>0.252757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432567</td>\n",
       "      <td>0.39017</td>\n",
       "      <td>0.42252</td>\n",
       "      <td>0.399318</td>\n",
       "      <td>0.431274</td>\n",
       "      <td>0.413506</td>\n",
       "      <td>0.360645</td>\n",
       "      <td>0.371753</td>\n",
       "      <td>0.394891</td>\n",
       "      <td>0.384053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <th>MRNA</th>\n",
       "      <td>0.11725</td>\n",
       "      <td>0.544065</td>\n",
       "      <td>0.593325</td>\n",
       "      <td>0.342374</td>\n",
       "      <td>0.353894</td>\n",
       "      <td>0.364903</td>\n",
       "      <td>0.458443</td>\n",
       "      <td>0.279531</td>\n",
       "      <td>0.437768</td>\n",
       "      <td>0.80797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394522</td>\n",
       "      <td>0.338536</td>\n",
       "      <td>0.41396</td>\n",
       "      <td>0.376794</td>\n",
       "      <td>0.403526</td>\n",
       "      <td>0.393114</td>\n",
       "      <td>0.323481</td>\n",
       "      <td>0.330641</td>\n",
       "      <td>0.343882</td>\n",
       "      <td>0.351716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-23</th>\n",
       "      <th>JD</th>\n",
       "      <td>0.257559</td>\n",
       "      <td>0.432068</td>\n",
       "      <td>0.594154</td>\n",
       "      <td>0.38258</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.735607</td>\n",
       "      <td>0.431549</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>0.427566</td>\n",
       "      <td>0.317445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439785</td>\n",
       "      <td>0.390341</td>\n",
       "      <td>0.434928</td>\n",
       "      <td>0.409699</td>\n",
       "      <td>0.439884</td>\n",
       "      <td>0.426104</td>\n",
       "      <td>0.371125</td>\n",
       "      <td>0.373449</td>\n",
       "      <td>0.404135</td>\n",
       "      <td>0.399308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-16</th>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.259288</td>\n",
       "      <td>0.489863</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>0.36388</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.575429</td>\n",
       "      <td>0.386898</td>\n",
       "      <td>0.479094</td>\n",
       "      <td>0.464529</td>\n",
       "      <td>0.43733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434836</td>\n",
       "      <td>0.385796</td>\n",
       "      <td>0.428566</td>\n",
       "      <td>0.40403</td>\n",
       "      <td>0.434419</td>\n",
       "      <td>0.42043</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.368383</td>\n",
       "      <td>0.400037</td>\n",
       "      <td>0.391843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.623975</td>\n",
       "      <td>0.498603</td>\n",
       "      <td>0.466236</td>\n",
       "      <td>0.469523</td>\n",
       "      <td>0.636301</td>\n",
       "      <td>0.523902</td>\n",
       "      <td>0.564498</td>\n",
       "      <td>0.687757</td>\n",
       "      <td>0.525219</td>\n",
       "      <td>0.421298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535316</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.530391</td>\n",
       "      <td>0.504917</td>\n",
       "      <td>0.535662</td>\n",
       "      <td>0.520131</td>\n",
       "      <td>0.464654</td>\n",
       "      <td>0.472194</td>\n",
       "      <td>0.496923</td>\n",
       "      <td>0.526663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentiment_0 sentiment_1 sentiment_2 sentiment_3 sentiment_4  \\\n",
       "day        ticker                                                               \n",
       "2021-09-21 AMZN      0.544879    0.257498    0.408812    0.368385    0.383385   \n",
       "2021-09-02 MRNA       0.11725    0.544065    0.593325    0.342374    0.353894   \n",
       "2021-08-23 JD        0.257559    0.432068    0.594154     0.38258    0.363372   \n",
       "2021-11-16 TSLA      0.259288    0.489863    0.543517     0.36388    0.386552   \n",
       "2021-06-11 TSLA      0.623975    0.498603    0.466236    0.469523    0.636301   \n",
       "\n",
       "                  sentiment_5 sentiment_6 sentiment_7 sentiment_8 sentiment_9  \\\n",
       "day        ticker                                                               \n",
       "2021-09-21 AMZN      0.416132    0.505084    0.382462    0.351178    0.252757   \n",
       "2021-09-02 MRNA      0.364903    0.458443    0.279531    0.437768     0.80797   \n",
       "2021-08-23 JD        0.735607    0.431549    0.390586    0.427566    0.317445   \n",
       "2021-11-16 TSLA      0.575429    0.386898    0.479094    0.464529     0.43733   \n",
       "2021-06-11 TSLA      0.523902    0.564498    0.687757    0.525219    0.421298   \n",
       "\n",
       "                   ... sentiment_50 sentiment_51 sentiment_52 sentiment_53  \\\n",
       "day        ticker  ...                                                       \n",
       "2021-09-21 AMZN    ...     0.432567      0.39017      0.42252     0.399318   \n",
       "2021-09-02 MRNA    ...     0.394522     0.338536      0.41396     0.376794   \n",
       "2021-08-23 JD      ...     0.439785     0.390341     0.434928     0.409699   \n",
       "2021-11-16 TSLA    ...     0.434836     0.385796     0.428566      0.40403   \n",
       "2021-06-11 TSLA    ...     0.535316       0.4889     0.530391     0.504917   \n",
       "\n",
       "                  sentiment_54 sentiment_55 sentiment_56 sentiment_57  \\\n",
       "day        ticker                                                       \n",
       "2021-09-21 AMZN       0.431274     0.413506     0.360645     0.371753   \n",
       "2021-09-02 MRNA       0.403526     0.393114     0.323481     0.330641   \n",
       "2021-08-23 JD         0.439884     0.426104     0.371125     0.373449   \n",
       "2021-11-16 TSLA       0.434419      0.42043       0.3663     0.368383   \n",
       "2021-06-11 TSLA       0.535662     0.520131     0.464654     0.472194   \n",
       "\n",
       "                  sentiment_58 sentiment_59  \n",
       "day        ticker                            \n",
       "2021-09-21 AMZN       0.394891     0.384053  \n",
       "2021-09-02 MRNA       0.343882     0.351716  \n",
       "2021-08-23 JD         0.404135     0.399308  \n",
       "2021-11-16 TSLA       0.400037     0.391843  \n",
       "2021-06-11 TSLA       0.496923     0.526663  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "embedded-effect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-03-04</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMGN</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANSS</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIIB</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topic_0  topic_1  topic_2  topic_3  topic_4\n",
       "day        ticker                                             \n",
       "2021-03-04 AAPL          2        2        2        2        2\n",
       "           AMGN          2        9        2        0        7\n",
       "           AMZN          2        2        2        2        2\n",
       "           ANSS          2        3        6        4        7\n",
       "           BIIB          2        2        1        0        7"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "fleet-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26491, 14)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "aerial-smoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4477, 40)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "spare-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26334, 5)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "located-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([financials, final_sentiment, topics], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "banned-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(columns = [column for column in final_df.columns if column.startswith(\"news\")], \n",
    "             axis = 1, inplace = True)\n",
    "final_df.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "auburn-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#int topic\n",
    "final_df[[col for col in final_df.columns if 'topic' in col]] = final_df[[col for col in \n",
    "                                                                          final_df.columns if 'topic' \n",
    "                                                                          in col]].apply(lambda col: col.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "classified-sacramento",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4477, 59)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "potential-edwards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adjclose</th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>rsi_6_sma</th>\n",
       "      <th>rsi_6_ema</th>\n",
       "      <th>rsi_12_sma</th>\n",
       "      <th>rsi_24_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_35</th>\n",
       "      <th>sentiment_36</th>\n",
       "      <th>sentiment_37</th>\n",
       "      <th>sentiment_38</th>\n",
       "      <th>sentiment_39</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2021-03-04</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>119.420219</td>\n",
       "      <td>124.660082</td>\n",
       "      <td>129.457326</td>\n",
       "      <td>131.775941</td>\n",
       "      <td>125.732602</td>\n",
       "      <td>128.423225</td>\n",
       "      <td>39.080453</td>\n",
       "      <td>33.325382</td>\n",
       "      <td>25.560048</td>\n",
       "      <td>29.139135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467013</td>\n",
       "      <td>0.433376</td>\n",
       "      <td>0.424253</td>\n",
       "      <td>0.410886</td>\n",
       "      <td>0.439668</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>2977.570068</td>\n",
       "      <td>3150.865967</td>\n",
       "      <td>3226.814465</td>\n",
       "      <td>3247.276636</td>\n",
       "      <td>3148.529560</td>\n",
       "      <td>3196.767470</td>\n",
       "      <td>24.214878</td>\n",
       "      <td>26.776597</td>\n",
       "      <td>27.150401</td>\n",
       "      <td>38.840834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518054</td>\n",
       "      <td>0.489071</td>\n",
       "      <td>0.472463</td>\n",
       "      <td>0.461305</td>\n",
       "      <td>0.488746</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>511.290009</td>\n",
       "      <td>542.648999</td>\n",
       "      <td>548.110004</td>\n",
       "      <td>549.791003</td>\n",
       "      <td>543.116656</td>\n",
       "      <td>543.017493</td>\n",
       "      <td>29.976383</td>\n",
       "      <td>44.271572</td>\n",
       "      <td>32.122175</td>\n",
       "      <td>49.305999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532548</td>\n",
       "      <td>0.510936</td>\n",
       "      <td>0.481093</td>\n",
       "      <td>0.474581</td>\n",
       "      <td>0.500493</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2021-03-05</th>\n",
       "      <th>AMGN</th>\n",
       "      <td>220.646820</td>\n",
       "      <td>220.581917</td>\n",
       "      <td>224.16998</td>\n",
       "      <td>228.93396</td>\n",
       "      <td>220.952093</td>\n",
       "      <td>224.423269</td>\n",
       "      <td>17.207729</td>\n",
       "      <td>21.321361</td>\n",
       "      <td>25.914517</td>\n",
       "      <td>24.227511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560588</td>\n",
       "      <td>0.51162</td>\n",
       "      <td>0.527688</td>\n",
       "      <td>0.506599</td>\n",
       "      <td>0.539568</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>3000.459961</td>\n",
       "      <td>3115.799976</td>\n",
       "      <td>3210.066467</td>\n",
       "      <td>3237.749642</td>\n",
       "      <td>3122.227793</td>\n",
       "      <td>3180.443527</td>\n",
       "      <td>24.72216</td>\n",
       "      <td>26.121193</td>\n",
       "      <td>26.326743</td>\n",
       "      <td>37.522669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454547</td>\n",
       "      <td>0.393381</td>\n",
       "      <td>0.453038</td>\n",
       "      <td>0.44455</td>\n",
       "      <td>0.472122</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      adjclose        ma_10        ma_20        ma_30  \\\n",
       "day        ticker                                                       \n",
       "2021-03-04 AAPL     119.420219   124.660082   129.457326   131.775941   \n",
       "           AMZN    2977.570068  3150.865967  3226.814465  3247.276636   \n",
       "           NFLX     511.290009   542.648999   548.110004   549.791003   \n",
       "2021-03-05 AMGN     220.646820   220.581917    224.16998    228.93396   \n",
       "           AMZN    3000.459961  3115.799976  3210.066467  3237.749642   \n",
       "\n",
       "                        ema_12       ema_26  rsi_6_sma  rsi_6_ema rsi_12_sma  \\\n",
       "day        ticker                                                              \n",
       "2021-03-04 AAPL     125.732602   128.423225  39.080453  33.325382  25.560048   \n",
       "           AMZN    3148.529560  3196.767470  24.214878  26.776597  27.150401   \n",
       "           NFLX     543.116656   543.017493  29.976383  44.271572  32.122175   \n",
       "2021-03-05 AMGN     220.952093   224.423269  17.207729  21.321361  25.914517   \n",
       "           AMZN    3122.227793  3180.443527   24.72216  26.121193  26.326743   \n",
       "\n",
       "                  rsi_24_sma  ...  sentiment_35  sentiment_36  sentiment_37  \\\n",
       "day        ticker             ...                                             \n",
       "2021-03-04 AAPL    29.139135  ...      0.467013      0.433376      0.424253   \n",
       "           AMZN    38.840834  ...      0.518054      0.489071      0.472463   \n",
       "           NFLX    49.305999  ...      0.532548      0.510936      0.481093   \n",
       "2021-03-05 AMGN    24.227511  ...      0.560588       0.51162      0.527688   \n",
       "           AMZN    37.522669  ...      0.454547      0.393381      0.453038   \n",
       "\n",
       "                   sentiment_38 sentiment_39 topic_0 topic_1 topic_2 topic_3  \\\n",
       "day        ticker                                                              \n",
       "2021-03-04 AAPL        0.410886     0.439668       2       2       2       2   \n",
       "           AMZN        0.461305     0.488746       2       2       2       2   \n",
       "           NFLX        0.474581     0.500493       2       7       6       2   \n",
       "2021-03-05 AMGN        0.506599     0.539568       2       2       8       3   \n",
       "           AMZN         0.44455     0.472122       2       2       2       2   \n",
       "\n",
       "                  topic_4  \n",
       "day        ticker          \n",
       "2021-03-04 AAPL         2  \n",
       "           AMZN         2  \n",
       "           NFLX         2  \n",
       "2021-03-05 AMGN         8  \n",
       "           AMZN         2  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "academic-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('/Users/polyanaboss/Desktop/Term paper/Data/processed_data_v.1.0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-reverse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
